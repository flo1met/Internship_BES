
@article{van_wonderen_bayesian_2024,
	title = {Bayesian evidence synthesis as a flexible alternative to meta-analysis: {A} simulation study and empirical demonstration},
	volume = {56},
	issn = {1554-3528},
	shorttitle = {Bayesian evidence synthesis as a flexible alternative to meta-analysis},
	url = {https://link.springer.com/10.3758/s13428-024-02350-2},
	doi = {10.3758/s13428-024-02350-2},
	abstract = {Synthesizing results across multiple studies is a popular way to increase the robustness of scientific findings. The most wellknown method for doing this is meta-analysis. However, because meta-analysis requires conceptually comparable effect sizes with the same statistical form, meta-analysis may not be possible when studies are highly diverse in terms of their research design, participant characteristics, or operationalization of key variables. In these situations, Bayesian evidence synthesis may constitute a flexible and feasible alternative, as this method combines studies at the hypothesis level rather than at the level of the effect size. This method therefore poses less constraints on the studies to be combined. In this study, we introduce Bayesian evidence synthesis and show through simulations when this method diverges from what would be expected in a meta-analysis to help researchers correctly interpret the synthesis results. As an empirical demonstration, we also apply Bayesian evidence synthesis to a published meta-analysis on statistical learning in people with and without developmental language disorder. We highlight the strengths and weaknesses of the proposed method and offer suggestions for future research.},
	language = {en},
	number = {4},
	urldate = {2024-08-16},
	journal = {Behavior Research Methods},
	author = {Van Wonderen, Elise and Zondervan-Zwijnenburg, Mariëlle and Klugkist, Irene},
	month = mar,
	year = {2024},
	pages = {4085--4102},
	file = {Van Wonderen et al. - 2024 - Bayesian evidence synthesis as a flexible alternat.pdf:C\:\\Users\\Florian\\Zotero\\storage\\LF8HR2WF\\Van Wonderen et al. - 2024 - Bayesian evidence synthesis as a flexible alternat.pdf:application/pdf},
}

@article{kevenaar_bayesian_2021,
	title = {Bayesian evidence synthesis in case of multi-cohort datasets: {An} illustration by multi-informant differences in self-control},
	volume = {47},
	issn = {18789293},
	shorttitle = {Bayesian evidence synthesis in case of multi-cohort datasets},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1878929320301535},
	doi = {10.1016/j.dcn.2020.100904},
	abstract = {The trend toward large-scale collaborative studies gives rise to the challenge of combining data from different sources efficiently. Here, we demonstrate how Bayesian evidence synthesis can be used to quantify and compare support for competing hypotheses and to aggregate this support over studies. We applied this method to study the ordering of multi-informant scores on the ASEBA Self Control Scale (ASCS), employing a multi-cohort design with data from four Dutch cohorts. Self-control reports were collected from mothers, fathers, teachers and children themselves. The available set of reporters differed between cohorts, so in each cohort varying com­ ponents of the overarching hypotheses were evaluated. We found consistent support for the partial hypothesis that parents reported more self-control problems than teachers. Furthermore, the aggregated results indicate most support for the combined hypothesis that children report most problem behaviors, followed by their mothers and fathers, and that teachers report the fewest problems. However, there was considerable inconsis­ tency across cohorts regarding the rank order of children’s reports. This article illustrates Bayesian evidence synthesis as a method when some of the cohorts only have data to evaluate a partial hypothesis. With Bayesian evidence synthesis, these cohorts can still contribute to the aggregated results.},
	language = {en},
	urldate = {2024-08-16},
	journal = {Developmental Cognitive Neuroscience},
	author = {Kevenaar, Sofieke T. and Zondervan-Zwijnenburg, Maria A.J. and Blok, Elisabet and Schmengler, Heiko and Fakkel, M. (Ties) and De Zeeuw, Eveline L. and Van Bergen, Elsje and Onland-Moret, N. Charlotte and Peeters, Margot and Hillegers, Manon H.J. and Boomsma, Dorret I. and Oldehinkel, Albertine J.},
	month = feb,
	year = {2021},
	pages = {100904},
	file = {Kevenaar et al. - 2021 - Bayesian evidence synthesis in case of multi-cohor.pdf:C\:\\Users\\Florian\\Zotero\\storage\\NT4UWPHP\\Kevenaar et al. - 2021 - Bayesian evidence synthesis in case of multi-cohor.pdf:application/pdf},
}

@article{klugkist_bayesian_2023,
	title = {Bayesian evidence synthesis for informative hypotheses: {An} introduction.},
	copyright = {http://www.apa.org/pubs/journals/resources/open-access.aspx},
	issn = {1939-1463, 1082-989X},
	shorttitle = {Bayesian evidence synthesis for informative hypotheses},
	url = {https://doi.apa.org/doi/10.1037/met0000602},
	doi = {10.1037/met0000602},
	abstract = {To establish a theory one needs cleverly designed and well-executed studies with appropriate and correctly interpreted statistical analyses. Equally important, one also needs replications of such studies and a way to combine the results of several replications into an accumulated state of knowledge. An approach that provides an appropriate and powerful analysis for studies targeting prespeciﬁed theories is the use of Bayesian informative hypothesis testing. An additional advantage of the use of this Bayesian approach is that combining the results from multiple studies is straightforward. In this article, we discuss the behavior of Bayes factors in the context of evaluating informative hypotheses with multiple studies. By using simple models and (partly) analytical solutions, we introduce and evaluate Bayesian evidence synthesis (BES) and compare its results to Bayesian sequential updating. By doing so, we clarify how different replications or updating questions can be evaluated. In addition, we illustrate BES with two simulations, in which multiple studies are generated to resemble conceptual replications. The studies in these simulations are too heterogeneous to be aggregated with conventional research synthesis methods.},
	language = {en},
	urldate = {2024-08-16},
	journal = {Psychological Methods},
	author = {Klugkist, Irene and Volker, Thom Benjamin},
	month = sep,
	year = {2023},
	file = {Klugkist und Volker - 2023 - Bayesian evidence synthesis for informative hypoth.pdf:C\:\\Users\\Florian\\Zotero\\storage\\5EB4E5GI\\Klugkist und Volker - 2023 - Bayesian evidence synthesis for informative hypoth.pdf:application/pdf},
}

@misc{volker_combining_2023,
	title = {Combining support for hypotheses over heterogeneous studies with {Bayesian} {Evidence} {Synthesis}: {A} simulation study},
	shorttitle = {Combining support for hypotheses over heterogeneous studies with {Bayesian} {Evidence} {Synthesis}},
	url = {http://arxiv.org/abs/2312.15032},
	abstract = {Scientific claims gain credibility by replicability, especially if replication under different circumstances and varying designs yields equivalent results. Aggregating results over multiple studies is, however, not straightforward, and when the heterogeneity between studies increases, conventional methods such as (Bayesian) meta-analysis and Bayesian sequential updating become infeasible. Bayesian Evidence Synthesis, built upon the foundations of the Bayes factor, allows to aggregate support for conceptually similar hypotheses over studies, regardless of methodological differences. We assess the performance of Bayesian Evidence Synthesis over multiple effect and sample sizes, with a broad set of (inequality-constrained) hypotheses using Monte Carlo simulations, focusing explicitly on the complexity of the hypotheses under consideration. The simulations show that this method can evaluate complex (informative) hypotheses regardless of methodological differences between studies, and performs adequately if the set of studies considered has sufficient statistical power. Additionally, we pinpoint challenging conditions that can lead to unsatisfactory results, and provide suggestions on handling these situations. Ultimately, we show that Bayesian Evidence Synthesis is a promising tool that can be used when traditional research synthesis methods are not applicable due to insurmountable between-study heterogeneity.},
	language = {en},
	urldate = {2024-08-16},
	publisher = {arXiv},
	author = {Volker, Thom Benjamin and Klugkist, Irene},
	month = dec,
	year = {2023},
	note = {arXiv:2312.15032 [stat]},
	keywords = {Statistics - Methodology},
	file = {Volker und Klugkist - 2023 - Combining support for hypotheses over heterogeneou.pdf:C\:\\Users\\Florian\\Zotero\\storage\\HA9YIXNK\\Volker und Klugkist - 2023 - Combining support for hypotheses over heterogeneou.pdf:application/pdf},
}

@article{kuiper_combining_2012,
	title = {Combining {Statistical} {Evidence} {From} {Several} {Studies}},
	language = {en},
	author = {Kuiper, Rebecca M and Buskens, Vincent and Raub, Werner and Hoijtink, Herbert},
	year = {2012},
	file = {Kuiper et al. - Combining Statistical Evidence From Several Studie.pdf:C\:\\Users\\Florian\\Zotero\\storage\\KCBJKNLH\\Kuiper et al. - Combining Statistical Evidence From Several Studie.pdf:application/pdf},
}

@article{mulder_bfpack_2021,
	title = {\textbf{{BFpack}} : {Flexible} {Bayes} {Factor} {Testing} of {Scientific} {Theories} in \textit{{R}}},
	volume = {100},
	issn = {1548-7660},
	shorttitle = {\textbf{{BFpack}}},
	url = {https://www.jstatsoft.org/v100/i18/},
	doi = {10.18637/jss.v100.i18},
	abstract = {There have been considerable methodological developments of Bayes factors for hypothesis testing in the social and behavioral sciences, and related ﬁelds. This development is due to the ﬂexibility of the Bayes factor for testing multiple hypotheses simultaneously, the ability to test complex hypotheses involving equality as well as order constraints on the parameters of interest, and the interpretability of the outcome as the weight of evidence provided by the data in support of competing scientiﬁc theories. The available software tools for Bayesian hypothesis testing are still limited however. In this paper we present a new R package called BFpack that contains functions for Bayes factor hypothesis testing for the many common testing problems. The software includes novel tools for (i) Bayesian exploratory testing (e.g., zero vs positive vs negative eﬀects), (ii) Bayesian conﬁrmatory testing (competing hypotheses with equality and/or order constraints), (iii) common statistical analyses, such as linear regression, generalized linear models, (multivariate) analysis of (co)variance, correlation analysis, and random intercept models, (iv) using default priors, and (v) while allowing data to contain missing observations that are missing at random.},
	language = {en},
	number = {18},
	urldate = {2024-08-22},
	journal = {Journal of Statistical Software},
	author = {Mulder, Joris and Williams, Donald R. and Gu, Xin and Tomarken, Andrew and Böing-Messing, Florian and Olsson-Collentine, Anton and Meijerink, Marlyne and Menke, Janosch and Van Aert, Robbie and Fox, Jean-Paul and Hoijtink, Herbert and Rosseel, Yves and Wagenmakers, Eric-Jan and Van Lissa, Caspar},
	year = {2021},
	file = {Mulder et al. - 2021 - BFpack  Flexible Bayes Factor Testing of S.pdf:C\:\\Users\\Florian\\Zotero\\storage\\VHR5EYAW\\Mulder et al. - 2021 - BFpack  Flexible Bayes Factor Testing of S.pdf:application/pdf},
}

@article{kass_bayes_1995,
	title = {Bayes {Factors}},
	volume = {90},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476572},
	doi = {10.1080/01621459.1995.10476572},
	abstract = {In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory. Bayes factors offer a way of evaluating evidence in favor of a null hypothesis. Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis. Bayes factors are very general and do not require alternative models to be nested. Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods. In “nonstandard” statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests. The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions. When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty. Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large. Bayes factors are useful for guiding an evolutionary model-building process. It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used.},
	number = {430},
	urldate = {2024-09-13},
	journal = {Journal of the American Statistical Association},
	author = {Kass, Robert E. and Raftery, Adrian E.},
	month = jun,
	year = {1995},
	note = {Publisher: ASA Website
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1995.10476572},
	keywords = {Bayesian hypothesis tests, BIC, Importance sampling, Laplace method, Markov chain Monte Carlo, Model selection, Monte Carlo integration, Posterior model probabilities, Posterior odds, Quadrature, Schwarz criterion, Sensitivity analysis, Strength of evidence},
	pages = {773--795},
}

@article{chib_marginal_1995,
	title = {Marginal {Likelihood} from the {Gibbs} {Output}},
	volume = {90},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635},
	doi = {10.1080/01621459.1995.10476635},
	abstract = {In the context of Bayes estimation via Gibbs sampling, with or without data augmentation, a simple approach is developed for computing the marginal density of the sample data (marginal likelihood) given parameter draws from the posterior distribution. Consequently, Bayes factors for model comparisons can be routinely computed as a by-product of the simulation. Hitherto, this calculation has proved extremely challenging. Our approach exploits the fact that the marginal density can be expressed as the prior times the likelihood function over the posterior density. This simple identity holds for any parameter value. An estimate of the posterior density is shown to be available if all complete conditional densities used in the Gibbs sampler have closed-form expressions. To improve accuracy, the posterior density is estimated at a high density point, and the numerical standard error of resulting estimate is derived. The ideas are applied to probit regression and finite mixture models.},
	number = {432},
	urldate = {2024-09-13},
	journal = {Journal of the American Statistical Association},
	author = {Chib, Siddhartha},
	month = dec,
	year = {1995},
	note = {Publisher: ASA Website
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1995.10476635},
	keywords = {Bayes factor, Estimation of normalizing constant, Finite mixture models, Linear regression, Markov chain Monte Carlo, Markov mixture model, Multivariate density estimation, Numerical standard error, Probit regression, Reduced conditional density},
	pages = {1313--1321},
}

@book{hoijtink_informative_2011,
	title = {Informative {Hypotheses}: {Theory} and {Practice} for {Behavioral} and {Social} {Scientists}},
	isbn = {978-1-4398-8052-4},
	shorttitle = {Informative {Hypotheses}},
	abstract = {When scientists formulate their theories, expectations, and hypotheses, they often use statements like: ``I expect mean A to be bigger than means B and C"; ``I expect that the relation between Y and both X1 and X2 is positive"; and ``I expect the relation between Y and X1 to be stronger than the relation between Y and X2". Stated otherwise, they fo},
	language = {en},
	publisher = {CRC Press},
	author = {Hoijtink, Herbert},
	month = oct,
	year = {2011},
	note = {Google-Books-ID: SzfOBQAAQBAJ},
	keywords = {Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Psychology / Movements / General, Psychology / Research \& Methodology},
	file = {Hoijtink - 2011 - Informative Hypotheses Theory and Practice for Be.pdf:C\:\\Users\\Florian\\Zotero\\storage\\P2E7YAIR\\Hoijtink - 2011 - Informative Hypotheses Theory and Practice for Be.pdf:application/pdf},
}

@article{klugkist_inequality_2005,
	title = {Inequality {Constrained} {Analysis} of {Variance}: {A} {Bayesian} {Approach}.},
	volume = {10},
	issn = {1939-1463, 1082-989X},
	shorttitle = {Inequality {Constrained} {Analysis} of {Variance}},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.10.4.477},
	doi = {10.1037/1082-989X.10.4.477},
	language = {en},
	number = {4},
	urldate = {2024-09-13},
	journal = {Psychological Methods},
	author = {Klugkist, Irene and Laudy, Olav and Hoijtink, Herbert},
	month = dec,
	year = {2005},
	pages = {477--493},
}

@article{hoijtink_tutorial_2019,
	title = {A tutorial on testing hypotheses using the {Bayes} factor},
	volume = {24},
	issn = {1939-1463},
	doi = {10.1037/met0000201},
	abstract = {Learning about hypothesis evaluation using the Bayes factor could enhance psychological research. In contrast to null-hypothesis significance testing it renders the evidence in favor of each of the hypotheses under consideration (it can be used to quantify support for the null-hypothesis) instead of a dichotomous reject/do-not-reject decision; it can straightforwardly be used for the evaluation of multiple hypotheses without having to bother about the proper manner to account for multiple testing; and it allows continuous reevaluation of hypotheses after additional data have been collected (Bayesian updating). This tutorial addresses researchers considering to evaluate their hypotheses by means of the Bayes factor. The focus is completely applied and each topic discussed is illustrated using Bayes factors for the evaluation of hypotheses in the context of an ANOVA model, obtained using the R package bain. Readers can execute all the analyses presented while reading this tutorial if they download bain and the R-codes used. It will be elaborated in a completely nontechnical manner: what the Bayes factor is, how it can be obtained, how Bayes factors should be interpreted, and what can be done with Bayes factors. After reading this tutorial and executing the associated code, researchers will be able to use their own data for the evaluation of hypotheses by means of the Bayes factor, not only in the context of ANOVA models, but also in the context of other statistical models. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	number = {5},
	journal = {Psychological Methods},
	author = {Hoijtink, Herbert and Mulder, Joris and van Lissa, Caspar and Gu, Xin},
	year = {2019},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Analysis of Variance, Errors, Hypothesis Testing, Null Hypothesis Testing, Statistical Probability, Statistical Significance},
	pages = {539--556},
	file = {Snapshot:C\:\\Users\\Florian\\Zotero\\storage\\IYSMMBFR\\2019-07157-001.html:text/html;Volltext:C\:\\Users\\Florian\\Zotero\\storage\\S7XJ5RNR\\Hoijtink et al. - 2019 - A tutorial on testing hypotheses using the Bayes f.pdf:application/pdf},
}

@article{wishart_generalised_1928,
	title = {The {Generalised} {Product} {Moment} {Distribution} in {Samples} from a {Normal} {Multivariate} {Population}},
	volume = {20A},
	issn = {0006-3444},
	url = {https://www.jstor.org/stable/2331939},
	doi = {10.2307/2331939},
	number = {1/2},
	urldate = {2024-09-15},
	journal = {Biometrika},
	author = {Wishart, John},
	year = {1928},
	note = {Publisher: [Oxford University Press, Biometrika Trust]},
	pages = {32--52},
	file = {JSTOR Full Text PDF:C\:\\Users\\Florian\\Zotero\\storage\\P6MZF357\\Wishart - 1928 - The Generalised Product Moment Distribution in Sam.pdf:application/pdf},
}

@book{r_core_team_r_2024,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2024},
}

@book{venables_modern_2002,
	address = {New York},
	edition = {Fourth},
	title = {Modern {Applied} {Statistics} with {S}},
	url = {https://www.stats.ox.ac.uk/pub/MASS4/},
	publisher = {Springer},
	author = {Venables, W. N. and Ripley, B. D.},
	year = {2002},
}

@article{kim_new_2016,
	title = {A new metric of absolute percentage error for intermittent demand forecasts},
	volume = {32},
	issn = {0169-2070},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207016000121},
	doi = {10.1016/j.ijforecast.2015.12.003},
	abstract = {The mean absolute percentage error (MAPE) is one of the most widely used measures of forecast accuracy, due to its advantages of scale-independency and interpretability. However, MAPE has the significant disadvantage that it produces infinite or undefined values for zero or close-to-zero actual values. In order to address this issue in MAPE, we propose a new measure of forecast accuracy called the mean arctangent absolute percentage error (MAAPE). MAAPE has been developed through looking at MAPE from a different angle. In essence, MAAPE is a slope as an angle, while MAPE is a slope as a ratio, considering a triangle with adjacent and opposite sides that are equal to an actual value and the difference between the actual and forecast values, respectively. MAAPE inherently preserves the philosophy of MAPE, overcoming the problem of division by zero by using bounded influences for outliers in a fundamental manner through considering the ratio as an angle instead of a slope. The theoretical properties of MAAPE are investigated, and the practical advantages are demonstrated using both simulated and real-life data.},
	number = {3},
	urldate = {2024-09-16},
	journal = {International Journal of Forecasting},
	author = {Kim, Sungil and Kim, Heeyoung},
	month = jul,
	year = {2016},
	keywords = {Accuracy measure, Forecast evaluation, Intermittent demand, MAPE},
	pages = {669--679},
	file = {ScienceDirect Snapshot:C\:\\Users\\Florian\\Zotero\\storage\\XQVP29DK\\S0169207016000121.html:text/html},
}

@article{barde_what_2012,
	title = {What to use to express the variability of data: {Standard} deviation or standard error of mean?},
	volume = {3},
	issn = {2229-3485},
	shorttitle = {What to use to express the variability of data},
	url = {https://journals.lww.com/picp/fulltext/2012/03030/what_to_use_to_express_the_variability_of_data_.7.aspx},
	doi = {10.4103/2229-3485.100662},
	abstract = {Statistics plays a vital role in biomedical research. It helps present data precisely and draws the meaningful conclusions. While presenting data, one should be aware of using adequate statistical measures. In biomedical journals, Standard Error of Mean (SEM) and Standard Deviation (SD) are used interchangeably to express the variability; though they measure different parameters. SEM quantifies uncertainty in estimate of the mean whereas SD indicates dispersion of the data from mean. As readers are generally interested in knowing the variability within sample, descriptive data should be precisely summarized with SD. Use of SEM should be limited to compute CI which measures the precision of population estimate. Journals can avoid such errors by requiring authors to adhere to their guidelines.},
	language = {en-US},
	number = {3},
	urldate = {2024-09-16},
	journal = {Perspectives in Clinical Research},
	author = {Barde, Mohini P. and Barde, Prajakt J.},
	month = sep,
	year = {2012},
	pages = {113},
	file = {Snapshot:C\:\\Users\\Florian\\Zotero\\storage\\74YSVZPS\\what_to_use_to_express_the_variability_of_data_.7.html:text/html;Volltext:C\:\\Users\\Florian\\Zotero\\storage\\69VUG8YX\\Barde und Barde - 2012 - What to use to express the variability of data St.pdf:application/pdf},
}

@article{lee_standard_2015,
	title = {Standard deviation and standard error of the mean},
	volume = {68},
	url = {https://synapse.koreamed.org/articles/1156109},
	doi = {10.4097/kjae.2015.68.3.220},
	number = {3},
	urldate = {2024-09-16},
	journal = {Korean Journal of Anesthesiology},
	author = {Lee, Dong Kyu and In, Junyong and Lee, Sangseok},
	month = may,
	year = {2015},
	note = {Publisher: The Korean Society of Anesthesiologists},
	pages = {220--223},
	file = {Full Text PDF:C\:\\Users\\Florian\\Zotero\\storage\\2B6TMT4Y\\Lee et al. - 2015 - Standard deviation and standard error of the mean.pdf:application/pdf},
}
